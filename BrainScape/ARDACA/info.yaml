note: "Note: This README file is Auto Generated."

title: "Age-related differences in auditory cortex activity during spoken word recognition"
  
description: |
  In the current study we investigated spoken word processing in young and
  older adult listeners in the absence of background noise. We compared
  paradigms requiring words to be repeated with "attentive listening" (no
  motor response required).

  Supplemental materials (including presentation scripts, stimuli,
  analysis scripts, extracted data, and figures) can be found at
  <https://osf.io/vmzag/>.

  **Materials:**
  
  Stimuli for this study were 375 monosyllabic consonant-vowel-consonant
  (CVC) words. The auditory stimuli were spoken versions of the above word
  sets recorded at 48,000 Hz using a 16-bit Digital-to-Analog converter
  with an Audio Technica 2045 microphone in a quiet room. Words were
  spoken by a female speaker with a standard American dialect.
  Root-mean-square (RMS) amplitude of the stimuli was equated across
  recordings. Out of the full set of words, 75 words were vocoded using a
  single channel with white noise as a carrier signal using jp_vocode.m
  from <http://github.com/jpeelle/jp_matlab>. These stimuli were used for
  an unintelligible baseline "noise" condition. The remaining 300 words
  were divided into 5 lists of 60 words, using MATCH software (Van
  Casteren and Davis, 2007), and were balanced for word frequency (as
  measured by the log of the Hyperspace Analogue to Language dataset;
  citation), orthographic length, concreteness, and familiarity. One of
  these lists was combined with 15 of the noise vocoded words and used for
  word repetition task practice outside of the scanner. The remaining four
  lists of 60 words served as the critical items inside the scanner, with
  half of the lists used for passive listening and the other half for word
  repetition. Word lists were counterbalanced participants such that each
  word was presented in both "listen" and "repeat" conditions across
  participants.

  **Participants:**
  
  Two groups of participants (young and older adults) were recruited for
  this study. The young adults were 29 healthy, right-handed adults, aged
  19-30 years (M = 23.8 , SD = 2.9), and were recruited via the Washington
  University in St. Louis Department of Psychology Subject Pool. Older
  adult participants were 31 healthy, right-handed, aged 65-81 years (M =
  71.0 , SD = 5.0).

  **Procedure:**
  
  Prior to scanning participants were taken to quiet room. During that
  time participants provided informed consent, completed demographic
  questionnaires, and a subset had their hearing tested using pure-tone
  audiometry. Participants were then instructed for the two tasks they
  would perform in the scanner: passive listening and word repetition.
  During passive listening, participants were asked to stay alert, still,
  and keep their eyes focused on a fixation while listening to a sequence
  auditory sounds including words, silence, and burst of noise
  (single-channel white noise vocoded words). During word repetition,
  participants were asked to do the same as in passive listening, with the
  addition of repeating the word they just head aloud. Participants were
  instructed to only repeat the words following the volume acquisitions
  after each word. Participants were told if they ever could not
  understand a word to give their best guess. Participants practiced a
  simulation of the word repetition task until the experimenter was
  confident that the participant understood the pacing and the nature of
  the task.

  Functional MRI scanning took place over the course of four scanning
  blocks, where participants alternated between blocks of passive
  listening and word repetition. The order of blocks was counterbalanced
  such that participants were equally likely to begin with a word
  repetition or passive listening block. During word repetition,
  participants' spoken responses were recorded using an in-bore Fibersound
  optical microphone. These responses were scored offline manually.

  **MRI data acquisition:**
  
  MRI data were acquired using a Siemens Prisma scanner (Siemens Medical
  Systems) at 3 T equipped with a 32-channel head coil. Scan sequences
  began with a T1-weighted structural volume using an MPRAGE sequence
  [repetition time (TR) = 2.4 s, echo time (TE) = 2.2 ms, flip angle = 8°,
  300 × 320 matrix, voxel size = 0.8 mm isotropic]. Blood oxygenation
  level-dependent (BOLD) functional MRI images were acquired using a
  multiband echo planar imaging sequence (Feinberg et al., 2010) [TR = 3
  s, TA = 1 s, TE = 37 ms, flip angle = 37°, 936 × 936 matrix, voxel size
  = 2 mm isotropic]. We used a sparse imaging design in which there was a
  delay in between scanning acquisitions, where the TR was longer than the
  acquisition time to allow for minimal scanning noise during stimulus
  presentation and audio recording of participant responses. 

  

usage_agreement: ""


license: "CC0"

citation: |
  @article{rogers2020age,
    title={Age-related differences in auditory cortex activity during spoken word recognition},
    author={Rogers, Chad S and Jones, Michael S and McConkey, Sarah and Spehar, Brent and Van Engen, Kristin J and Sommers, Mitchell S and Peelle, Jonathan E},
    journal={Neurobiology of Language},
    volume={1},
    number={4},
    pages={452--473},
    year={2020},
    publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
  }

download: "https://openneuro.org/datasets/ds002382/versions/1.0.1"